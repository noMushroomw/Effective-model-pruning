{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6928d5d9",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4c39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1c176",
   "metadata": {},
   "source": [
    "# track neff and sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41656e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_block(module:nn.Module, beta=1.0, method='magnitude') -> torch.Tensor:\n",
    "    x = module.weight.data\n",
    "    x = x.view(-1)\n",
    "    if method == 'mean':\n",
    "        x = x - torch.mean(x)\n",
    "    x_norm = torch.abs(x) / torch.sum(torch.abs(x))\n",
    "    neff = 1/torch.sum((x_norm ** 2))\n",
    "    r_neff = torch.floor(beta * neff)\n",
    "    r_neff = r_neff.clamp(min=1, max=len(x)-1)\n",
    "\n",
    "    _, indices = torch.sort(x_norm, descending=True)\n",
    "    range_tensor = torch.arange(len(x), device=x.device)\n",
    "    sorted_mask = range_tensor < r_neff\n",
    "\n",
    "    mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "    mask.scatter_(0, indices, sorted_mask)\n",
    "    mask = mask.view_as(module.weight)\n",
    "    return mask, r_neff\n",
    "\n",
    "def model_block(model, renormalize=False, beta=1.0, method='magnitude'):\n",
    "    model = copy.deepcopy(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            mask, neff = mask_block(module, beta=beta, method=method)\n",
    "            mask = mask.to(module.weight.device)\n",
    "            n = module.weight.data.numel()\n",
    "            with torch.no_grad():\n",
    "                module.weight *= mask\n",
    "                if renormalize:\n",
    "                    module.weight.mul_(n / neff)\n",
    "    return model, neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6b3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_params += param.numel()\n",
    "            zero_params += torch.sum(param == 0).item()\n",
    "    \n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity\n",
    "\n",
    "def per_layer_neff(model):\n",
    "    neff = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            layer_neff = torch.sum(param != 0).item()\n",
    "            neff[name] = layer_neff\n",
    "    return neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb1a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Testing function\n",
    "def test(model, device, test_loader, times=1):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for _ in range(times):\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(test_loss)\n",
    "\n",
    "    if times == 1:\n",
    "        return test_loss, accuracy\n",
    "    \n",
    "    else:\n",
    "        return loss_list, accuracy_list, sum(accuracy_list)/times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d100aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_loaders(dataset_name, batch_size=128, test_batch_size=1000, data_root='./data'):\n",
    "    \"\"\"\n",
    "    Returns: train_loader, test_loader, input_size, num_classes, meta (dict)\n",
    "    \"\"\"\n",
    "    name = dataset_name.lower()\n",
    "    meta = {}\n",
    "\n",
    "    # Generic normalizations (safe defaults). If you want canonical stats, compute them once.\n",
    "    NORM_1C = transforms.Normalize((0.5,), (0.5,))\n",
    "    NORM_3C = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "    if name == 'mnist':\n",
    "        # (You already have this; included for completeness.)\n",
    "        tfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train = datasets.MNIST(data_root, train=True, download=True, transform=tfm)\n",
    "        test  = datasets.MNIST(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "\n",
    "    elif name == 'fashionmnist':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_1C])\n",
    "        train = datasets.FashionMNIST(data_root, train=True, download=True, transform=tfm)\n",
    "        test  = datasets.FashionMNIST(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "        \n",
    "    elif name == 'cifar10':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.CIFAR10(data_root, train=True,  download=True, transform=tfm)\n",
    "        test  = datasets.CIFAR10(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 10\n",
    "\n",
    "    elif name == 'cifar100':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.CIFAR100(data_root, train=True,  download=True, transform=tfm)\n",
    "        test  = datasets.CIFAR100(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 100\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=test_batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, test_loader, inp, ncls, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc3c1f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "MNIST_model_configs = {\n",
    "    'Model_1': {\n",
    "        'hidden_size': [16],\n",
    "        'lr': 1e-4,\n",
    "        'epochs': 5,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'Model_2': {\n",
    "        'hidden_size': [512, 128, 32],\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'Model_3': {\n",
    "        'hidden_size': [1024, 512, 256, 128, 32],\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 25,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5444f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 1.0237, Train Accuracy: 73.47%, Test Loss: 0.5058, Test Accuracy: 87.42%\n",
      "Epoch 2: Train Loss: 0.4370, Train Accuracy: 88.33%, Test Loss: 0.3679, Test Accuracy: 90.12%\n",
      "Epoch 3: Train Loss: 0.3558, Train Accuracy: 90.05%, Test Loss: 0.3238, Test Accuracy: 90.88%\n",
      "Epoch 4: Train Loss: 0.3221, Train Accuracy: 90.88%, Test Loss: 0.3024, Test Accuracy: 91.41%\n",
      "Epoch 5: Train Loss: 0.3028, Train Accuracy: 91.32%, Test Loss: 0.2873, Test Accuracy: 91.76%\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 0.3360, Train Accuracy: 90.08%, Test Loss: 0.1486, Test Accuracy: 95.62%\n",
      "Epoch 2: Train Loss: 0.1264, Train Accuracy: 96.24%, Test Loss: 0.0995, Test Accuracy: 96.93%\n",
      "Epoch 3: Train Loss: 0.0845, Train Accuracy: 97.43%, Test Loss: 0.0853, Test Accuracy: 97.34%\n",
      "Epoch 4: Train Loss: 0.0610, Train Accuracy: 98.15%, Test Loss: 0.0866, Test Accuracy: 97.21%\n",
      "Epoch 5: Train Loss: 0.0470, Train Accuracy: 98.51%, Test Loss: 0.0635, Test Accuracy: 97.95%\n",
      "Epoch 6: Train Loss: 0.0361, Train Accuracy: 98.88%, Test Loss: 0.0709, Test Accuracy: 97.66%\n",
      "Epoch 7: Train Loss: 0.0281, Train Accuracy: 99.04%, Test Loss: 0.0714, Test Accuracy: 97.83%\n",
      "Epoch 8: Train Loss: 0.0229, Train Accuracy: 99.26%, Test Loss: 0.0676, Test Accuracy: 97.88%\n",
      "Epoch 9: Train Loss: 0.0176, Train Accuracy: 99.44%, Test Loss: 0.0748, Test Accuracy: 97.70%\n",
      "Epoch 10: Train Loss: 0.0164, Train Accuracy: 99.45%, Test Loss: 0.0751, Test Accuracy: 97.87%\n",
      "Epoch 11: Train Loss: 0.0113, Train Accuracy: 99.64%, Test Loss: 0.0843, Test Accuracy: 97.83%\n",
      "Epoch 12: Train Loss: 0.0114, Train Accuracy: 99.60%, Test Loss: 0.0849, Test Accuracy: 97.84%\n",
      "Epoch 13: Train Loss: 0.0099, Train Accuracy: 99.69%, Test Loss: 0.0901, Test Accuracy: 97.71%\n",
      "Epoch 14: Train Loss: 0.0097, Train Accuracy: 99.69%, Test Loss: 0.0885, Test Accuracy: 97.69%\n",
      "Epoch 15: Train Loss: 0.0085, Train Accuracy: 99.72%, Test Loss: 0.0936, Test Accuracy: 97.82%\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 0.3342, Train Accuracy: 90.02%, Test Loss: 0.1563, Test Accuracy: 95.25%\n",
      "Epoch 2: Train Loss: 0.1154, Train Accuracy: 96.51%, Test Loss: 0.1084, Test Accuracy: 96.63%\n",
      "Epoch 3: Train Loss: 0.0742, Train Accuracy: 97.75%, Test Loss: 0.0791, Test Accuracy: 97.52%\n",
      "Epoch 4: Train Loss: 0.0542, Train Accuracy: 98.32%, Test Loss: 0.0903, Test Accuracy: 97.32%\n",
      "Epoch 5: Train Loss: 0.0428, Train Accuracy: 98.65%, Test Loss: 0.0769, Test Accuracy: 97.68%\n",
      "Epoch 6: Train Loss: 0.0333, Train Accuracy: 98.91%, Test Loss: 0.0673, Test Accuracy: 98.11%\n",
      "Epoch 7: Train Loss: 0.0270, Train Accuracy: 99.13%, Test Loss: 0.0706, Test Accuracy: 98.08%\n",
      "Epoch 8: Train Loss: 0.0234, Train Accuracy: 99.25%, Test Loss: 0.0786, Test Accuracy: 97.81%\n",
      "Epoch 9: Train Loss: 0.0201, Train Accuracy: 99.36%, Test Loss: 0.0804, Test Accuracy: 97.91%\n",
      "Epoch 10: Train Loss: 0.0182, Train Accuracy: 99.46%, Test Loss: 0.0816, Test Accuracy: 98.09%\n",
      "Epoch 11: Train Loss: 0.0169, Train Accuracy: 99.45%, Test Loss: 0.0817, Test Accuracy: 98.10%\n",
      "Epoch 12: Train Loss: 0.0152, Train Accuracy: 99.52%, Test Loss: 0.0882, Test Accuracy: 97.88%\n",
      "Epoch 13: Train Loss: 0.0112, Train Accuracy: 99.66%, Test Loss: 0.0964, Test Accuracy: 97.84%\n",
      "Epoch 14: Train Loss: 0.0133, Train Accuracy: 99.58%, Test Loss: 0.0926, Test Accuracy: 97.94%\n",
      "Epoch 15: Train Loss: 0.0122, Train Accuracy: 99.61%, Test Loss: 0.0781, Test Accuracy: 98.02%\n",
      "Epoch 16: Train Loss: 0.0095, Train Accuracy: 99.70%, Test Loss: 0.0957, Test Accuracy: 98.13%\n",
      "Epoch 17: Train Loss: 0.0102, Train Accuracy: 99.70%, Test Loss: 0.0848, Test Accuracy: 97.99%\n",
      "Epoch 18: Train Loss: 0.0092, Train Accuracy: 99.71%, Test Loss: 0.1004, Test Accuracy: 97.97%\n",
      "Epoch 19: Train Loss: 0.0116, Train Accuracy: 99.64%, Test Loss: 0.0793, Test Accuracy: 98.37%\n",
      "Epoch 20: Train Loss: 0.0096, Train Accuracy: 99.69%, Test Loss: 0.0790, Test Accuracy: 98.31%\n",
      "Epoch 21: Train Loss: 0.0053, Train Accuracy: 99.85%, Test Loss: 0.0946, Test Accuracy: 98.12%\n",
      "Epoch 22: Train Loss: 0.0099, Train Accuracy: 99.69%, Test Loss: 0.0839, Test Accuracy: 98.30%\n",
      "Epoch 23: Train Loss: 0.0073, Train Accuracy: 99.78%, Test Loss: 0.0821, Test Accuracy: 98.24%\n",
      "Epoch 24: Train Loss: 0.0082, Train Accuracy: 99.75%, Test Loss: 0.0818, Test Accuracy: 98.32%\n",
      "Epoch 25: Train Loss: 0.0094, Train Accuracy: 99.73%, Test Loss: 0.1003, Test Accuracy: 97.91%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset setup\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "dataset_name = 'mnist'\n",
    "\n",
    "train_loader, test_loader, input_size, num_classes, meta = get_loaders(dataset_name, batch_size, test_batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in MNIST_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    os.makedirs(f'models/{dataset_name}', exist_ok=True)\n",
    "    model.save(f'models/{dataset_name}/{model_name}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51728711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "fashion_mnist_model_configs = {\n",
    "    'Model_1': {\n",
    "        'hidden_size': [32],\n",
    "        'lr': 1e-4,\n",
    "        'epochs': 5,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'Model_2': {\n",
    "        'hidden_size': [512, 128, 32],\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'Model_3': {\n",
    "        'hidden_size': [1024, 512, 256, 128, 32],\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 25,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbccb2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 32 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 0.9275, Train Accuracy: 70.41%, Test Loss: 0.6359, Test Accuracy: 78.09%\n",
      "Epoch 2: Train Loss: 0.5641, Train Accuracy: 80.59%, Test Loss: 0.5504, Test Accuracy: 80.47%\n",
      "Epoch 3: Train Loss: 0.5043, Train Accuracy: 82.55%, Test Loss: 0.5129, Test Accuracy: 81.69%\n",
      "Epoch 4: Train Loss: 0.4735, Train Accuracy: 83.59%, Test Loss: 0.4946, Test Accuracy: 82.21%\n",
      "Epoch 5: Train Loss: 0.4542, Train Accuracy: 84.17%, Test Loss: 0.4790, Test Accuracy: 83.13%\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 0.5816, Train Accuracy: 79.49%, Test Loss: 0.4531, Test Accuracy: 83.49%\n",
      "Epoch 2: Train Loss: 0.3988, Train Accuracy: 85.62%, Test Loss: 0.4021, Test Accuracy: 85.48%\n",
      "Epoch 3: Train Loss: 0.3553, Train Accuracy: 87.03%, Test Loss: 0.3781, Test Accuracy: 86.53%\n",
      "Epoch 4: Train Loss: 0.3277, Train Accuracy: 88.02%, Test Loss: 0.3751, Test Accuracy: 86.35%\n",
      "Epoch 5: Train Loss: 0.3057, Train Accuracy: 88.75%, Test Loss: 0.3788, Test Accuracy: 86.22%\n",
      "Epoch 6: Train Loss: 0.2888, Train Accuracy: 89.22%, Test Loss: 0.3526, Test Accuracy: 87.57%\n",
      "Epoch 7: Train Loss: 0.2726, Train Accuracy: 89.79%, Test Loss: 0.3500, Test Accuracy: 87.58%\n",
      "Epoch 8: Train Loss: 0.2607, Train Accuracy: 90.32%, Test Loss: 0.3396, Test Accuracy: 87.64%\n",
      "Epoch 9: Train Loss: 0.2477, Train Accuracy: 90.72%, Test Loss: 0.3275, Test Accuracy: 88.27%\n",
      "Epoch 10: Train Loss: 0.2360, Train Accuracy: 91.20%, Test Loss: 0.3392, Test Accuracy: 88.23%\n",
      "Epoch 11: Train Loss: 0.2258, Train Accuracy: 91.64%, Test Loss: 0.3640, Test Accuracy: 87.19%\n",
      "Epoch 12: Train Loss: 0.2169, Train Accuracy: 91.91%, Test Loss: 0.3355, Test Accuracy: 88.28%\n",
      "Epoch 13: Train Loss: 0.2055, Train Accuracy: 92.33%, Test Loss: 0.3510, Test Accuracy: 87.98%\n",
      "Epoch 14: Train Loss: 0.1976, Train Accuracy: 92.60%, Test Loss: 0.3478, Test Accuracy: 88.35%\n",
      "Epoch 15: Train Loss: 0.1888, Train Accuracy: 92.96%, Test Loss: 0.3459, Test Accuracy: 88.37%\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Epoch 1: Train Loss: 0.5968, Train Accuracy: 78.29%, Test Loss: 0.4878, Test Accuracy: 82.50%\n",
      "Epoch 2: Train Loss: 0.3983, Train Accuracy: 85.61%, Test Loss: 0.4142, Test Accuracy: 84.91%\n",
      "Epoch 3: Train Loss: 0.3538, Train Accuracy: 87.09%, Test Loss: 0.3792, Test Accuracy: 86.42%\n",
      "Epoch 4: Train Loss: 0.3243, Train Accuracy: 88.03%, Test Loss: 0.3697, Test Accuracy: 86.80%\n",
      "Epoch 5: Train Loss: 0.3026, Train Accuracy: 88.86%, Test Loss: 0.3558, Test Accuracy: 87.14%\n",
      "Epoch 6: Train Loss: 0.2837, Train Accuracy: 89.41%, Test Loss: 0.3471, Test Accuracy: 87.37%\n",
      "Epoch 7: Train Loss: 0.2663, Train Accuracy: 90.06%, Test Loss: 0.3373, Test Accuracy: 88.13%\n",
      "Epoch 8: Train Loss: 0.2504, Train Accuracy: 90.61%, Test Loss: 0.3423, Test Accuracy: 88.26%\n",
      "Epoch 9: Train Loss: 0.2388, Train Accuracy: 91.07%, Test Loss: 0.3286, Test Accuracy: 88.76%\n",
      "Epoch 10: Train Loss: 0.2286, Train Accuracy: 91.55%, Test Loss: 0.3278, Test Accuracy: 88.82%\n",
      "Epoch 11: Train Loss: 0.2141, Train Accuracy: 92.11%, Test Loss: 0.3424, Test Accuracy: 88.70%\n",
      "Epoch 12: Train Loss: 0.2050, Train Accuracy: 92.30%, Test Loss: 0.3579, Test Accuracy: 88.53%\n",
      "Epoch 13: Train Loss: 0.1921, Train Accuracy: 92.88%, Test Loss: 0.3713, Test Accuracy: 87.95%\n",
      "Epoch 14: Train Loss: 0.1819, Train Accuracy: 93.19%, Test Loss: 0.3938, Test Accuracy: 88.00%\n",
      "Epoch 15: Train Loss: 0.1709, Train Accuracy: 93.58%, Test Loss: 0.3487, Test Accuracy: 88.99%\n",
      "Epoch 16: Train Loss: 0.1636, Train Accuracy: 93.95%, Test Loss: 0.3510, Test Accuracy: 88.60%\n",
      "Epoch 17: Train Loss: 0.1534, Train Accuracy: 94.32%, Test Loss: 0.3583, Test Accuracy: 89.18%\n",
      "Epoch 18: Train Loss: 0.1471, Train Accuracy: 94.46%, Test Loss: 0.3724, Test Accuracy: 88.99%\n",
      "Epoch 19: Train Loss: 0.1392, Train Accuracy: 94.77%, Test Loss: 0.3765, Test Accuracy: 88.75%\n",
      "Epoch 20: Train Loss: 0.1274, Train Accuracy: 95.22%, Test Loss: 0.4104, Test Accuracy: 88.90%\n",
      "Epoch 21: Train Loss: 0.1246, Train Accuracy: 95.32%, Test Loss: 0.3641, Test Accuracy: 89.53%\n",
      "Epoch 22: Train Loss: 0.1155, Train Accuracy: 95.74%, Test Loss: 0.4053, Test Accuracy: 88.91%\n",
      "Epoch 23: Train Loss: 0.1123, Train Accuracy: 95.75%, Test Loss: 0.4107, Test Accuracy: 89.01%\n",
      "Epoch 24: Train Loss: 0.1066, Train Accuracy: 96.01%, Test Loss: 0.4058, Test Accuracy: 89.69%\n",
      "Epoch 25: Train Loss: 0.0988, Train Accuracy: 96.26%, Test Loss: 0.4639, Test Accuracy: 89.48%\n"
     ]
    }
   ],
   "source": [
    "# Dataset setup\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "dataset_name = 'fashionmnist'\n",
    "\n",
    "train_loader, test_loader, input_size, num_classes, meta = get_loaders(dataset_name, batch_size, test_batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in fashion_mnist_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    os.makedirs(f'models/{dataset_name}', exist_ok=True)\n",
    "    model.save(f'models/{dataset_name}/{model_name}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1715bd",
   "metadata": {},
   "source": [
    "## pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed6b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "result = {\n",
    "    'model_name': [],\n",
    "    'test_accuracy': [],\n",
    "    'model_sparsity': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 12,730\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 89.04%, sparsity: 0.3664\n",
      "pb magnitude renormalized pruning test accuracy: 89.08%, sparsity: 0.3664\n",
      "mean block mean pruning test accuracy: 89.47%, sparsity: 0.3841\n",
      "mean block mean renormalized pruning test accuracy: 89.37%, sparsity: 0.3841\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 472,042\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 97.58%, sparsity: 0.4238\n",
      "pb magnitude renormalized pruning test accuracy: 97.59%, sparsity: 0.4238\n",
      "mean block mean pruning test accuracy: 97.60%, sparsity: 0.4244\n",
      "mean block mean renormalized pruning test accuracy: 97.56%, sparsity: 0.4244\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 1,497,322\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 97.77%, sparsity: 0.4179\n",
      "pb magnitude renormalized pruning test accuracy: 97.76%, sparsity: 0.4179\n",
      "mean block mean pruning test accuracy: 97.94%, sparsity: 0.4206\n",
      "mean block mean renormalized pruning test accuracy: 97.88%, sparsity: 0.4206\n"
     ]
    }
   ],
   "source": [
    "datasets_name = 'mnist'\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "for model_name, config in MNIST_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "    \n",
    "    # magnitude renormalized\n",
    "    pb_model, pb_neff = model_block(model, renormalize=True, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude_renorm\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "    \n",
    "    # mean renormalized\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=True, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean_renorm\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"pb magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"pb magnitude renormalized pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean block mean renormalized pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a40fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "result = {\n",
    "    'model_name': [],\n",
    "    'test_accuracy': [],\n",
    "    'model_sparsity': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e3e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 32 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 25,450\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 81.59%, sparsity: 0.3765\n",
      "pb magnitude renormalized pruning test accuracy: 81.64%, sparsity: 0.3765\n",
      "mean block mean pruning test accuracy: 82.15%, sparsity: 0.3785\n",
      "mean block mean renormalized pruning test accuracy: 82.21%, sparsity: 0.3785\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 472,042\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 87.59%, sparsity: 0.4128\n",
      "pb magnitude renormalized pruning test accuracy: 87.37%, sparsity: 0.4128\n",
      "mean block mean pruning test accuracy: 87.22%, sparsity: 0.4130\n",
      "mean block mean renormalized pruning test accuracy: 87.22%, sparsity: 0.4130\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 1,497,322\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 89.01%, sparsity: 0.4313\n",
      "pb magnitude renormalized pruning test accuracy: 89.05%, sparsity: 0.4313\n",
      "mean block mean pruning test accuracy: 88.78%, sparsity: 0.4308\n",
      "mean block mean renormalized pruning test accuracy: 88.72%, sparsity: 0.4308\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'fashionmnist'\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "for model_name, config in fashion_mnist_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "    \n",
    "    # magnitude renormalized\n",
    "    pb_model, pb_neff = model_block(model, renormalize=True, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude_renorm\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "    \n",
    "    # mean renormalized\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=True, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean_renorm\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"pb magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"pb magnitude renormalized pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean block mean renormalized pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684f0c5",
   "metadata": {},
   "source": [
    "## beta swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba5117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 12,730\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 68.07%, sparsity: 0.6832\n",
      "pb magnitude renormalized pruning test accuracy: 68.30%, sparsity: 0.6832\n",
      "mean block mean pruning test accuracy: 66.13%, sparsity: 0.6921\n",
      "mean block mean renormalized pruning test accuracy: 65.29%, sparsity: 0.6921\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 77.29%, sparsity: 0.5248\n",
      "pb magnitude renormalized pruning test accuracy: 77.09%, sparsity: 0.5248\n",
      "mean block mean pruning test accuracy: 75.74%, sparsity: 0.5382\n",
      "mean block mean renormalized pruning test accuracy: 75.93%, sparsity: 0.5382\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 89.04%, sparsity: 0.3664\n",
      "pb magnitude renormalized pruning test accuracy: 89.08%, sparsity: 0.3664\n",
      "mean block mean pruning test accuracy: 89.47%, sparsity: 0.3841\n",
      "mean block mean renormalized pruning test accuracy: 89.37%, sparsity: 0.3841\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 91.82%, sparsity: 0.2080\n",
      "pb magnitude renormalized pruning test accuracy: 91.83%, sparsity: 0.2080\n",
      "mean block mean pruning test accuracy: 91.58%, sparsity: 0.2302\n",
      "mean block mean renormalized pruning test accuracy: 91.62%, sparsity: 0.2302\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_1, test accuracy: 91.76%\n",
      "pb magnitude pruning test accuracy: 91.75%, sparsity: 0.0508\n",
      "pb magnitude renormalized pruning test accuracy: 91.78%, sparsity: 0.0508\n",
      "mean block mean pruning test accuracy: 91.73%, sparsity: 0.0775\n",
      "mean block mean renormalized pruning test accuracy: 91.77%, sparsity: 0.0775\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 472,042\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 93.25%, sparsity: 0.7119\n",
      "pb magnitude renormalized pruning test accuracy: 93.36%, sparsity: 0.7119\n",
      "mean block mean pruning test accuracy: 95.86%, sparsity: 0.7122\n",
      "mean block mean renormalized pruning test accuracy: 95.85%, sparsity: 0.7122\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 96.98%, sparsity: 0.5679\n",
      "pb magnitude renormalized pruning test accuracy: 96.98%, sparsity: 0.5679\n",
      "mean block mean pruning test accuracy: 96.92%, sparsity: 0.5683\n",
      "mean block mean renormalized pruning test accuracy: 96.89%, sparsity: 0.5683\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 97.58%, sparsity: 0.4238\n",
      "pb magnitude renormalized pruning test accuracy: 97.59%, sparsity: 0.4238\n",
      "mean block mean pruning test accuracy: 97.60%, sparsity: 0.4244\n",
      "mean block mean renormalized pruning test accuracy: 97.56%, sparsity: 0.4244\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 97.82%, sparsity: 0.2798\n",
      "pb magnitude renormalized pruning test accuracy: 97.78%, sparsity: 0.2798\n",
      "mean block mean pruning test accuracy: 97.75%, sparsity: 0.2804\n",
      "mean block mean renormalized pruning test accuracy: 97.74%, sparsity: 0.2804\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_2, test accuracy: 97.82%\n",
      "pb magnitude pruning test accuracy: 97.84%, sparsity: 0.1359\n",
      "pb magnitude renormalized pruning test accuracy: 97.84%, sparsity: 0.1359\n",
      "mean block mean pruning test accuracy: 97.85%, sparsity: 0.1366\n",
      "mean block mean renormalized pruning test accuracy: 97.82%, sparsity: 0.1366\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 1,497,322\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 96.28%, sparsity: 0.7090\n",
      "pb magnitude renormalized pruning test accuracy: 96.10%, sparsity: 0.7090\n",
      "mean block mean pruning test accuracy: 95.60%, sparsity: 0.7103\n",
      "mean block mean renormalized pruning test accuracy: 95.82%, sparsity: 0.7103\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 97.86%, sparsity: 0.5634\n",
      "pb magnitude renormalized pruning test accuracy: 97.77%, sparsity: 0.5634\n",
      "mean block mean pruning test accuracy: 97.75%, sparsity: 0.5654\n",
      "mean block mean renormalized pruning test accuracy: 97.58%, sparsity: 0.5654\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 97.77%, sparsity: 0.4179\n",
      "pb magnitude renormalized pruning test accuracy: 97.76%, sparsity: 0.4179\n",
      "mean block mean pruning test accuracy: 97.94%, sparsity: 0.4206\n",
      "mean block mean renormalized pruning test accuracy: 97.88%, sparsity: 0.4206\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 97.96%, sparsity: 0.2724\n",
      "pb magnitude renormalized pruning test accuracy: 97.89%, sparsity: 0.2724\n",
      "mean block mean pruning test accuracy: 97.92%, sparsity: 0.2757\n",
      "mean block mean renormalized pruning test accuracy: 97.90%, sparsity: 0.2757\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_3, test accuracy: 97.91%\n",
      "pb magnitude pruning test accuracy: 97.93%, sparsity: 0.1270\n",
      "pb magnitude renormalized pruning test accuracy: 97.91%, sparsity: 0.1270\n",
      "mean block mean pruning test accuracy: 97.95%, sparsity: 0.1310\n",
      "mean block mean renormalized pruning test accuracy: 97.92%, sparsity: 0.1310\n"
     ]
    }
   ],
   "source": [
    "beta_values = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "beta_results = {}\n",
    "\n",
    "for model_name, config in MNIST_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    for beta in beta_values:\n",
    "        print(f\"\\n--- Beta: {beta} ---\")\n",
    "        # Results storage\n",
    "        result = {\n",
    "            'model_name': [],\n",
    "            'test_accuracy': [],\n",
    "            'model_sparsity': [],\n",
    "        }\n",
    "    \n",
    "        # magnitude\n",
    "        pb_model, pb_neff = model_block(model, renormalize=False, beta=beta, method='magnitude')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_magnitude\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "        \n",
    "        # magnitude renormalized\n",
    "        pb_model, pb_neff = model_block(model, renormalize=True, beta=beta, method='magnitude')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_magnitude_renorm\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "        # mean\n",
    "        mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=beta, method='mean')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_mean\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "        \n",
    "        # mean renormalized\n",
    "        mean_pb_model, mean_pb_neff = model_block(model, renormalize=True, beta=beta, method='mean')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_mean_renorm\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "        beta_results[beta] = result\n",
    "\n",
    "        # summary\n",
    "        print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "        print(f\"pb magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "        print(f\"pb magnitude renormalized pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "        print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "        print(f\"mean block mean renormalized pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49210b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 32 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 25,450\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 61.73%, sparsity: 0.6882\n",
      "pb magnitude renormalized pruning test accuracy: 61.90%, sparsity: 0.6882\n",
      "mean block mean pruning test accuracy: 66.96%, sparsity: 0.6893\n",
      "mean block mean renormalized pruning test accuracy: 67.19%, sparsity: 0.6893\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 80.85%, sparsity: 0.5324\n",
      "pb magnitude renormalized pruning test accuracy: 81.08%, sparsity: 0.5324\n",
      "mean block mean pruning test accuracy: 77.21%, sparsity: 0.5339\n",
      "mean block mean renormalized pruning test accuracy: 76.92%, sparsity: 0.5339\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 81.59%, sparsity: 0.3765\n",
      "pb magnitude renormalized pruning test accuracy: 81.64%, sparsity: 0.3765\n",
      "mean block mean pruning test accuracy: 82.15%, sparsity: 0.3785\n",
      "mean block mean renormalized pruning test accuracy: 82.21%, sparsity: 0.3785\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 82.93%, sparsity: 0.2206\n",
      "pb magnitude renormalized pruning test accuracy: 82.99%, sparsity: 0.2206\n",
      "mean block mean pruning test accuracy: 82.91%, sparsity: 0.2231\n",
      "mean block mean renormalized pruning test accuracy: 82.88%, sparsity: 0.2231\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_1, test accuracy: 83.13%\n",
      "pb magnitude pruning test accuracy: 83.12%, sparsity: 0.0659\n",
      "pb magnitude renormalized pruning test accuracy: 83.12%, sparsity: 0.0659\n",
      "mean block mean pruning test accuracy: 83.06%, sparsity: 0.0690\n",
      "mean block mean renormalized pruning test accuracy: 83.05%, sparsity: 0.0690\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 512 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 472,042\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 73.72%, sparsity: 0.7064\n",
      "pb magnitude renormalized pruning test accuracy: 73.80%, sparsity: 0.7064\n",
      "mean block mean pruning test accuracy: 76.32%, sparsity: 0.7065\n",
      "mean block mean renormalized pruning test accuracy: 77.38%, sparsity: 0.7065\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 83.71%, sparsity: 0.5596\n",
      "pb magnitude renormalized pruning test accuracy: 83.97%, sparsity: 0.5596\n",
      "mean block mean pruning test accuracy: 87.10%, sparsity: 0.5598\n",
      "mean block mean renormalized pruning test accuracy: 86.81%, sparsity: 0.5598\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 87.59%, sparsity: 0.4128\n",
      "pb magnitude renormalized pruning test accuracy: 87.37%, sparsity: 0.4128\n",
      "mean block mean pruning test accuracy: 87.22%, sparsity: 0.4130\n",
      "mean block mean renormalized pruning test accuracy: 87.22%, sparsity: 0.4130\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 88.35%, sparsity: 0.2660\n",
      "pb magnitude renormalized pruning test accuracy: 88.12%, sparsity: 0.2660\n",
      "mean block mean pruning test accuracy: 88.36%, sparsity: 0.2663\n",
      "mean block mean renormalized pruning test accuracy: 88.25%, sparsity: 0.2663\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_2, test accuracy: 88.37%\n",
      "pb magnitude pruning test accuracy: 88.37%, sparsity: 0.1192\n",
      "pb magnitude renormalized pruning test accuracy: 88.21%, sparsity: 0.1192\n",
      "mean block mean pruning test accuracy: 88.48%, sparsity: 0.1196\n",
      "mean block mean renormalized pruning test accuracy: 88.30%, sparsity: 0.1196\n",
      "\n",
      "============================================================\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> 128 -> 32 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 25, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 1,497,322\n",
      "\n",
      "--- Beta: 0.5 ---\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 81.99%, sparsity: 0.7156\n",
      "pb magnitude renormalized pruning test accuracy: 81.86%, sparsity: 0.7156\n",
      "mean block mean pruning test accuracy: 82.72%, sparsity: 0.7154\n",
      "mean block mean renormalized pruning test accuracy: 82.33%, sparsity: 0.7154\n",
      "\n",
      "--- Beta: 0.75 ---\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 86.85%, sparsity: 0.5735\n",
      "pb magnitude renormalized pruning test accuracy: 86.66%, sparsity: 0.5735\n",
      "mean block mean pruning test accuracy: 87.13%, sparsity: 0.5731\n",
      "mean block mean renormalized pruning test accuracy: 87.23%, sparsity: 0.5731\n",
      "\n",
      "--- Beta: 1.0 ---\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 89.01%, sparsity: 0.4313\n",
      "pb magnitude renormalized pruning test accuracy: 89.05%, sparsity: 0.4313\n",
      "mean block mean pruning test accuracy: 88.78%, sparsity: 0.4308\n",
      "mean block mean renormalized pruning test accuracy: 88.72%, sparsity: 0.4308\n",
      "\n",
      "--- Beta: 1.25 ---\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 89.16%, sparsity: 0.2891\n",
      "pb magnitude renormalized pruning test accuracy: 89.20%, sparsity: 0.2891\n",
      "mean block mean pruning test accuracy: 89.25%, sparsity: 0.2885\n",
      "mean block mean renormalized pruning test accuracy: 89.21%, sparsity: 0.2885\n",
      "\n",
      "--- Beta: 1.5 ---\n",
      "model name: Model_3, test accuracy: 89.48%\n",
      "pb magnitude pruning test accuracy: 89.43%, sparsity: 0.1470\n",
      "pb magnitude renormalized pruning test accuracy: 89.48%, sparsity: 0.1470\n",
      "mean block mean pruning test accuracy: 89.40%, sparsity: 0.1463\n",
      "mean block mean renormalized pruning test accuracy: 89.33%, sparsity: 0.1463\n"
     ]
    }
   ],
   "source": [
    "beta_values = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "beta_results = {}\n",
    "dataset_name = 'fashionmnist'\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "for model_name, config in fashion_mnist_model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    for beta in beta_values:\n",
    "        print(f\"\\n--- Beta: {beta} ---\")\n",
    "        # Results storage\n",
    "        result = {\n",
    "            'model_name': [],\n",
    "            'test_accuracy': [],\n",
    "            'model_sparsity': [],\n",
    "        }\n",
    "    \n",
    "        # magnitude\n",
    "        pb_model, pb_neff = model_block(model, renormalize=False, beta=beta, method='magnitude')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_magnitude\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "        \n",
    "        # magnitude renormalized\n",
    "        pb_model, pb_neff = model_block(model, renormalize=True, beta=beta, method='magnitude')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_magnitude_renorm\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "        # mean\n",
    "        mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=beta, method='mean')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_mean\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "        \n",
    "        # mean renormalized\n",
    "        mean_pb_model, mean_pb_neff = model_block(model, renormalize=True, beta=beta, method='mean')\n",
    "        test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "        result['model_name'].append(f\"{model_name}_pb_{beta}_mean_renorm\")\n",
    "        result['test_accuracy'].append(accuracy_mean)\n",
    "        result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "        beta_results[beta] = result\n",
    "\n",
    "        # summary\n",
    "        print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "        print(f\"pb magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "        print(f\"pb magnitude renormalized pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "        print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "        print(f\"mean block mean renormalized pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c27ae7",
   "metadata": {},
   "source": [
    "# not test yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6504e5a",
   "metadata": {},
   "source": [
    "# Different activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeaaff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class with optional dropout\n",
    "class geluLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(geluLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.gelu(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "# Model class with optional dropout\n",
    "class SigmoidLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(SigmoidLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.sigmoid(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "        \n",
    "# Model class with optional dropout\n",
    "class tanhLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(tanhLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.tanh(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "model_configs = {\n",
    "    'Model_1_Underfit': {\n",
    "        'hidden_size': [64, 32, 16],  # Very shallow, only 1 small hidden layer\n",
    "        'lr': 1e-4,  # Lower learning rate\n",
    "        'epochs': 5,  # Fewer epochs\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Underfitted: Too simple (1 layer, 32 units)'\n",
    "    },\n",
    "    'Model_2_Slight_Underfit': {\n",
    "        'hidden_size': [256, 128, 64],  # 2 small layers\n",
    "        'lr': 5e-4,\n",
    "        'epochs': 8,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Slightly underfitted: Simple architecture'\n",
    "    },\n",
    "    'Model_3_Well_Trained': {\n",
    "        'hidden_size': [512, 256, 128],  # Moderate depth and width\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.2,  # Some regularization\n",
    "        'description': 'Well-trained: Balanced architecture with dropout'\n",
    "    },\n",
    "    'Model_4_Well_Trained_Deep': {\n",
    "        'hidden_size': [1024, 512, 256],  # Deeper but with dropout\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 20,\n",
    "        'dropout': 0.3,  # More dropout for regularization\n",
    "        'description': 'Well-trained: Deeper with good regularization'\n",
    "    },\n",
    "    'Model_5_Overfit': {\n",
    "        'hidden_size': [2048, 1024, 1024],  # Very deep and wide\n",
    "        'lr': 1e-3,  # Higher learning rate\n",
    "        'epochs': 30,  # Many epochs\n",
    "        'dropout': 0.0,  # No regularization\n",
    "        'description': 'Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_6_Extra_Overfit': {\n",
    "        'hidden_size': [4096, 2048, 1024],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 50,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_7_Extra_Overfit': {\n",
    "        'hidden_size': [8192, 4096, 2048],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 100,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model1 = geluLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model1.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model1, device, train_loader, optimizer, epoch)\n",
    "    model1.save(f'models/MNIST_model/gelu_{model_name}.pth')\n",
    "    \n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model2 = SigmoidLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model2.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model2, device, train_loader, optimizer, epoch)\n",
    "    model2.save(f'models/MNIST_model/sigmoid_{model_name}.pth')\n",
    "    \n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model3 = tanhLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model3.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model3, device, train_loader, optimizer, epoch)\n",
    "    model3.save(f'models/MNIST_model/tanh_{model_name}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56501ce",
   "metadata": {},
   "source": [
    "# GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = geluLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/gelu_{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0bbbb",
   "metadata": {},
   "source": [
    "# SIGMOID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SigmoidLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/sigmoid_{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3431c",
   "metadata": {},
   "source": [
    "# TANH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = tanhLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/tanh_{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(origin_test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
